# SwarmUI StableDiffusion.cpp Backend

A high-performance backend for SwarmUI using [stable-diffusion.cpp](https://github.com/leejet/stable-diffusion.cpp) - enabling fast, efficient image generation with Flux, SD3, SDXL, video models, and more in optimized C++/CUDA.

## ‚ú® Features

### Core Capabilities
- ‚úÖ **Flux Models** - Full support for FLUX.1-dev, FLUX.1-schnell, and FLUX.2-dev with automatic component management
- ‚úÖ **SD3/SD3.5** - Complete multi-component architecture support (CLIP-G, CLIP-L, T5-XXL)
- ‚úÖ **Z-Image Models** - Support for Z-Image Turbo models with Qwen LLM integration
- ‚úÖ **SDXL/SD1.5/SD2** - Full support for all standard Stable Diffusion architectures
- ‚úÖ **Video Generation** - Wan 2.1/2.2 video models with text-to-video and image-to-video
- ‚úÖ **GGUF Format** - Native support for quantized GGUF models (Q2_K, Q4_K, Q8_0, etc.)
- ‚úÖ **LoRA Support** - Full LoRA integration with automatic directory detection
- ‚úÖ **ControlNet** - Experimental ControlNet support for compatible models
- ‚úÖ **Live Previews** - Real-time TAESD preview images during generation
- ‚úÖ **Auto-Update** - Automatic SD.cpp binary downloads and updates from GitHub releases

### Performance Optimization
- ‚úÖ **Inference Caching** - cache-dit/ucache/easycache for 5-10x speedup on repeat generations
- ‚úÖ **Memory Mapping** - `--mmap` for faster model loading and reduced RAM usage
- ‚úÖ **VAE Optimization** - Direct convolution (`--vae-conv-direct`) for faster decoding
- ‚úÖ **VAE Tiling** - Reduces VRAM usage by processing in tiles
- ‚úÖ **CPU Offloading** - Move VAE/CLIP to CPU to save VRAM
- ‚úÖ **Flash Attention** - Memory-efficient attention mechanism

### Platform Support
- ‚úÖ **CUDA** - Optimized for NVIDIA GPUs (CUDA 11.x and 12.x with auto-detection)
- ‚úÖ **CPU** - Universal fallback with AVX/AVX2 support
- ‚úÖ **Vulkan** - Cross-platform GPU acceleration (experimental for Flux)

## üöÄ Quick Start

### Installation

1. **Enable the Extension**
   - This extension comes pre-installed with SwarmUI
   - Go to `Server ‚Üí Extensions` in SwarmUI
   - Enable "SD.cpp Backend"
   - Restart SwarmUI

2. **First Run**
   - On first launch, the extension will automatically download the SD.cpp binary for your platform
   - Choose your device (CPU, CUDA, or Vulkan) in the backend settings
   - The extension will select the appropriate CUDA version automatically

3. **Add Models**
   - Place your models in `Models/Stable-Diffusion/`
   - The backend supports:
     - GGUF models (Q2_K, Q4_K, Q8_0 quantization)
     - SafeTensors models
     - CKPT/BIN files

## üì¶ Model Setup

### Flux Models

Flux models require four components. The backend will **automatically download** missing components on first use.

**Main Model** (`Models/Stable-Diffusion/`):
- `flux1-dev-Q2_K.gguf` or `flux1-dev.safetensors`
- `flux1-schnell-Q4_K.gguf` or `flux1-schnell.safetensors`
- Download from: [FLUX.1 on Hugging Face](https://huggingface.co/black-forest-labs/FLUX.1-dev)

**VAE** (`Models/VAE/` or auto-download):
- `ae.safetensors` or `Flux/ae.safetensors`
- Auto-downloads from: https://huggingface.co/mcmonkey/swarm-vaes

**Text Encoders** (`Models/clip/` or auto-download):
- `clip_l.safetensors` - Auto-downloads from Stability AI
- `t5xxl_fp8_e4m3fn.safetensors` - Auto-downloads (FP8 version for lower VRAM)

**Quantization Recommendations:**
| VRAM | Quantization | Quality | Speed |
|------|--------------|---------|-------|
| 12GB+ | Q8_0 | Highest | Slower |
| 8-10GB | Q4_K | Good | Fast |
| 6-8GB | Q4_0 | Fair | Faster |
| 4-6GB | Q2_K | Lower | Fastest |

### SD3/SD3.5 Models

SD3 models are similar to Flux:

**Main Model** (`Models/Stable-Diffusion/`):
- `sd3.5_large.safetensors`
- `sd3_medium.safetensors`

**Required Components** (auto-download):
- CLIP-G encoder
- CLIP-L encoder
- T5-XXL encoder

### Z-Image Models

Z-Image models use a Qwen LLM instead of T5-XXL:

**Main Model** (`Models/Stable-Diffusion/`):
- `z_image_turbo.safetensors`

**Required Components** (auto-download):
- VAE (Flux VAE)
- Qwen 3 4B LLM (`qwen_3_4b.safetensors`)

### Video Models (Wan 2.1/2.2)

Wan models for video generation:

**Main Model** (`Models/Stable-Diffusion/`):
- `wan_2.1.safetensors` or `wan_2.2.safetensors`

**Features:**
- Text-to-video generation
- Image-to-video animation
- Dual-model system for Wan 2.2 (high-noise model support)
- Flow-shift parameter (default 3.0)

### SDXL/SD1.5/SD2 Models

Standard Stable Diffusion models work out of the box:

**Supported Formats:**
- `.safetensors` (recommended)
- `.ckpt` (legacy)
- `.gguf` (quantized)

**Model Types:**
- SDXL (1024x1024)
- SDXL-Turbo (4-8 steps)
- SD 1.5 (512x512)
- SD 1.5 Turbo
- SD 2.x (768x768)
- LCM models

## ‚öôÔ∏è Configuration

### Backend Settings

Access settings via `Server ‚Üí Backends ‚Üí SD.cpp Backend`

**Device Selection:**
- `CPU` - Universal, works on any system (slower)
- `CUDA` - NVIDIA GPUs (best performance)
- `Vulkan` - Any modern GPU (experimental for Flux)

**CUDA Version** (Auto-detects):
- `Auto` - Automatically detects your CUDA installation (recommended)
- `CUDA 11.x` - For older NVIDIA drivers (450+)
- `CUDA 12.x` - For newer NVIDIA drivers (525+)
- `CUDA 13.x` - Uses CUDA 12 binaries (forward compatible)

**Auto-Update:**
- Enabled by default
- Checks GitHub for SD.cpp updates on startup
- Downloads latest version automatically

### Performance Parameters

**SD.cpp Performance Group** (Advanced Settings):

| Parameter | Default | Description |
|-----------|---------|-------------|
| Memory Map Models | `true` | Faster loading, reduced RAM usage |
| VAE Direct Convolution | `true` | Significantly faster VAE decoding |
| Cache Mode | `auto` | Inference caching (cache-dit for Flux, ucache for SD/SDXL) |
| Cache Preset | `fast` | Cache quality/speed (slow/medium/fast/ultra) |

**Cache Modes:**
- `auto` - Automatically selects best mode (recommended)
- `cache-dit` - For Flux/DiT models (5-10x speedup)
- `ucache` - For SD/SDXL/UNET models
- `easycache` - Simple condition-level cache
- `none` - Disable caching

**Cache Presets** (only with cache-dit):
- `ultra` - Maximum speed, slight quality trade-off
- `fast` - Balanced speed/quality (recommended)
- `medium` - Better quality, moderate speedup
- `slow` - Best quality, minimal speedup

**SD.cpp Group** (Standard Settings):

| Parameter | Default | Description |
|-----------|---------|-------------|
| VAE Tiling | `true` | Reduce VRAM usage (recommended for <12GB VRAM) |
| VAE on CPU | `false` | Offload VAE to CPU (if running out of VRAM) |
| CLIP on CPU | `false` | Offload CLIP to CPU (if running out of VRAM) |
| Flash Attention | `false` | Memory-efficient attention (may reduce quality slightly) |
| SD.cpp Sampler | `euler` | Sampling method (euler for Flux, euler_a for SD/SDXL) |
| SD.cpp Scheduler | `(empty)` | Scheduler type (discrete, karras, exponential, ays, gits) |
| TAESD Preview Decoder | `(None)` | Fast preview decoder for live previews |
| ESRGAN Upscale Model | `(None)` | Post-processing upscaler |
| Upscale Repeats | `1` | Number of upscale passes |
| Color Projection | `false` | Color correction for img2img consistency |

## üí° Usage Tips

### Flux Best Practices

1. **CFG Scale**: Always use 1.0 (backend enforces this)
2. **Sampler**: euler sampler works best (auto-selected)
3. **Steps**:
   - Flux-dev: 20+ steps recommended (4-step minimum)
   - Flux-schnell: 4 steps optimized
4. **Negative Prompts**: Not effective with Flux models
5. **Caching**: Enable cache-dit with `ultra` preset for maximum speed on repeat generations

### Performance Optimization

**For Best Speed:**
1. Enable "Cache Mode" set to `auto` or `cache-dit`
2. Set "Cache Preset" to `ultra` or `fast`
3. Enable "Memory Map Models"
4. Enable "VAE Direct Convolution"
5. Use quantized GGUF models (Q4_K or Q8_0)
6. First generation builds cache (slow), subsequent generations are 5-10x faster

**For Limited VRAM:**
1. Enable "VAE Tiling"
2. Enable "VAE on CPU" and "CLIP on CPU"
3. Use lower quantization (Q2_K, Q4_0)
4. Reduce image dimensions
5. Close other GPU applications

### LoRA Usage

LoRA syntax: `<lora:model_name:strength>`

Example: `beautiful landscape <lora:detail-enhancer:0.8>`

**Important:**
- Place LoRA files in `Models/Lora/`
- Backend automatically detects LoRA directory
- Flux LoRAs work best with Q8_0 quantization

### Video Generation (Wan Models)

Video-specific parameters:
- **Video Frames**: Number of frames to generate
- **Video FPS**: Frames per second
- **Flow Shift**: Flow control (default 3.0 for Wan)
- **Wan 2.2**: Supports dual-model system with high-noise diffusion model

## üõ†Ô∏è Troubleshooting

### Slow Generation (2-3 minutes for Flux)

**Problem:** Generation taking much longer than expected

**Solution:**
1. Ensure you have the latest SD.cpp binary (check version: `master-1896b28` or newer)
2. Enable performance optimizations:
   - "Cache Mode" ‚Üí `auto`
   - "Cache Preset" ‚Üí `ultra`
   - "Memory Map Models" ‚Üí `true`
   - "VAE Direct Convolution" ‚Üí `true`
3. Use quantized GGUF models (Q4_K or Q8_0)
4. First generation builds cache (slow), next generations are 5-10x faster
5. Verify you're using CUDA (not CPU) backend
6. Check that cache-dit mode is being used (logs will show `--cache-mode cache-dit`)

### Missing Required Components

**Problem:** "Missing components: VAE (ae.safetensors)" or similar

**Solution:**
- Components should auto-download on first use
- If download fails, manually download missing files:
  - VAE: https://huggingface.co/mcmonkey/swarm-vaes/resolve/main/flux_ae.safetensors
  - CLIP-L: https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/text_encoder/model.fp16.safetensors
  - T5-XXL: https://huggingface.co/mcmonkey/google_t5-v1_1-xxl_encoderonly/resolve/main/t5xxl_fp8_e4m3fn.safetensors
- Place in `Models/VAE/` or `Models/clip/`
- Refresh models in SwarmUI

### CUDA Runtime Error

**Problem:** "SD.cpp CUDA binary failed to start" or missing DLL errors

**Solution:**
1. Install CUDA 12.x Toolkit: https://developer.nvidia.com/cuda-12-6-0-download-archive
2. Or switch to CPU backend in settings
3. Backend will automatically fallback to CPU if CUDA fails

### No Preview Images

**Problem:** Live previews not showing during generation

**Solution:**
- Backend automatically enables TAESD previews
- Previews require SD.cpp `master-1896b28` or newer
- Check logs to verify `--preview tae` is being used
- Previews update every step or every 500ms

### Out of Memory

**Problem:** CUDA out of memory or allocation failed

**Solution:**
1. Enable "VAE Tiling"
2. Enable "VAE on CPU"
3. Use lower quantization (Q2_K instead of Q8_0)
4. Reduce image dimensions
5. Close other GPU applications
6. For Flux: Use Q4_0 quantization on 8GB GPUs

### Invalid Scheduler Error

**Problem:** `error: invalid scheduler default`

**Solution:**
- Leave "SD.cpp Scheduler" parameter empty or untoggled
- Backend automatically uses SD.cpp's default scheduler
- If set, use: discrete, karras, exponential, ays, or gits

## üìä Architecture Support

| Model Type | Status | Notes |
|------------|--------|-------|
| **Flux** |
| FLUX.1-dev | ‚úÖ Full | Requires 4 components, GGUF preferred |
| FLUX.1-schnell | ‚úÖ Full | 4-step variant |
| FLUX.2-dev | ‚úÖ Full | Latest Flux architecture |
| **SD3** |
| SD3 Medium | ‚úÖ Full | Multi-component like Flux |
| SD3.5 Large | ‚úÖ Full | Multi-component architecture |
| **Z-Image** |
| Z-Image Turbo | ‚úÖ Full | Uses Qwen LLM, auto-downloads components |
| **SDXL** |
| SDXL Base | ‚úÖ Full | Standard safetensors/ckpt |
| SDXL Turbo | ‚úÖ Full | 4-8 step variant |
| SDXL Lightning | ‚úÖ Full | Fast inference variant |
| **SD 1.x/2.x** |
| SD 1.5 | ‚úÖ Full | 512x512 resolution |
| SD 1.5 Turbo | ‚úÖ Full | Fast variant |
| SD 2.x | ‚úÖ Full | 768x768 resolution |
| **LCM** |
| LCM Models | ‚úÖ Full | 2-8 step inference |
| LCM LoRA | ‚úÖ Full | LoRA-based LCM |
| **Video** |
| Wan 2.1 | ‚úÖ Full | Text-to-video, image-to-video |
| Wan 2.2 | ‚úÖ Full | Dual-model system |

## üé® Advanced Features

### Img2Img and Inpainting

- **Init Image**: Automatic img2img support
- **Init Image Creativity**: Strength parameter (0.0-1.0)
- **Mask Image**: Inpainting with mask support

### ControlNet (Experimental)

- SD.cpp supports single ControlNet
- Backend will warn if multiple ControlNets used
- ControlNet model + control image required
- Control strength parameter (0.0-2.0)

### Batch Generation

- Batch count parameter (generates multiple images)
- SD.cpp `--batch-count` flag
- All images saved and returned

### ESRGAN Upscaling

- Post-processing upscaler
- Supports RealESRGAN models
- Multiple upscale passes supported
- Place upscale models in `Models/upscale_model/`

## üèóÔ∏è Technical Architecture

### Extension Structure

```
SwarmUI-SD.cpp-Backend/
‚îú‚îÄ‚îÄ SDcppExtension.cs              # Main extension entry point
‚îú‚îÄ‚îÄ SwarmBackends/
‚îÇ   ‚îî‚îÄ‚îÄ SDcppBackend.cs            # Backend implementation (~400 lines, refactored)
‚îú‚îÄ‚îÄ Models/
‚îÇ   ‚îú‚îÄ‚îÄ SDcppModelManager.cs       # Model detection, validation, downloads
‚îÇ   ‚îî‚îÄ‚îÄ SDcppParameterBuilder.cs   # Parameter conversion to SD.cpp CLI format
‚îú‚îÄ‚îÄ Utils/
‚îÇ   ‚îú‚îÄ‚îÄ SDcppDownloadManager.cs    # Auto-download SD.cpp binaries
‚îÇ   ‚îî‚îÄ‚îÄ SDcppProcessManager.cs     # Process execution and output capture
‚îî‚îÄ‚îÄ WebAPI/
    ‚îî‚îÄ‚îÄ SDcppAPI.cs                # Additional API endpoints
```

### Code Design Principles

- **Separation of Concerns**: Model management, parameter building, and backend logic are separate
- **SwarmUI Integration**: Uses SwarmUI utilities (`Utilities.DownloadFile`, model management)
- **Automatic Fallbacks**: CUDA ‚Üí CPU fallback, auto-component downloads
- **Clean Architecture**: Reduced from 1391 lines to ~400 lines in main backend

### File Format Support

**Model Formats:**
- `.gguf` - Native SD.cpp format (Q2_K, Q4_K, Q8_0 quantization)
- `.safetensors` - Standard format (recommended)
- `.ckpt`, `.bin` - Legacy formats
- `.sft` - Shortened safetensors

**Image Formats:**
- PNG output (default)
- JPG/JPEG support

## üîÑ Update System

The backend automatically checks for SD.cpp updates on startup:

1. Queries GitHub API for latest release
2. Compares with installed version
3. Downloads newer version if available
4. Preserves user settings during updates

**Manual Update:**
- Delete `dlbackend/sdcpp/cuda12/sdcpp_version.json` (or cuda11, cpu, vulkan)
- Restart SwarmUI
- Latest version will download automatically

## üìà Performance Benchmarks

**Flux-dev (1024x1024, 20 steps, Q8_0):**
| Hardware | First Gen | Cached Gen | Speedup |
|----------|-----------|------------|---------|
| RTX 4090 | ~50s | ~8-10s | 5-6x |
| RTX 3080 | ~80s | ~15-20s | 4-5x |
| RTX 3060 12GB | ~120s | ~25-30s | 4x |

**Flux-schnell (1024x1024, 4 steps, Q4_K):**
| Hardware | Time |
|----------|------|
| RTX 4090 | ~8-12s |
| RTX 3080 | ~15-20s |
| RTX 3060 | ~25-30s |

*With cache-dit mode enabled and ultra preset*

## ü§ù Contributing

Contributions welcome! Focus areas:
- Additional model architecture support (AnimateDiff, etc.)
- Performance profiling and optimization
- Better error messages and user guidance
- UI/UX improvements

## üìÑ License

MIT License

## üôè Credits

- [stable-diffusion.cpp](https://github.com/leejet/stable-diffusion.cpp) by leejet - Core inference engine
- [SwarmUI](https://github.com/mcmonkeyprojects/SwarmUI) by mcmonkey - UI framework
- Flux models by [Black Forest Labs](https://huggingface.co/black-forest-labs)
- SD3 models by [Stability AI](https://stability.ai/)

---

**Last Updated:** January 2026
**Extension Version:** 0.1.0
**Minimum SD.cpp Version:** master-1896b28 (for full performance features)
